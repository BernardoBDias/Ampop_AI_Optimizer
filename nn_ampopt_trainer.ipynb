{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1006\n",
      "[3.1064598e+01 6.1659500e+04 5.8053015e+06]\n"
     ]
    }
   ],
   "source": [
    "with open('database_ampop.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    header = next(reader)  # Lê a primeira linha como cabeçalho (opcional)\n",
    "    data_base = [list(map(float, row)) for row in reader]\n",
    "\n",
    "data_base = torch.tensor(data_base)\n",
    "X_medidas = data_base[:,-3:].numpy()\n",
    "Y_larguras = data_base[:,:-3].numpy()\n",
    "\n",
    "print(len(X_medidas))\n",
    "# print(Y_larguras[0,:])\n",
    "print(X_medidas[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01093262 0.00053323 0.34648305]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "size_data_test = 0.2\n",
    "hidden_size1 = 8\n",
    "hidden_size2 = 8\n",
    "learning_rate = 0.01\n",
    "batch_size = 32\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_Y = MinMaxScaler()\n",
    "\n",
    "X_normalized = scaler_X.fit_transform(X_medidas)\n",
    "Y_normalized = scaler_Y.fit_transform(Y_larguras)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_normalized, Y_normalized, test_size=size_data_test)\n",
    "print(X_normalized[0,:])\n",
    "\n",
    "X_train = torch.Tensor(X_train)\n",
    "X_val = torch.Tensor(X_val)\n",
    "Y_train = torch.Tensor(Y_train)\n",
    "Y_val = torch.Tensor(Y_val)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "val_dataset = TensorDataset(X_val, Y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmpOpT_NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(3,hidden_size1)\n",
    "        self.h_layer1 = nn.Linear(hidden_size1,hidden_size2)\n",
    "        self.h_layer2 = nn.Linear(hidden_size2,5)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.input_layer(x))\n",
    "        out = self.relu(self.h_layer1(out))\n",
    "        out = self.h_layer2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/1000, Train Loss: 0.0535, Val Loss: 0.0509\n",
      "Epoch 200/1000, Train Loss: 0.0516, Val Loss: 0.0482\n",
      "Epoch 300/1000, Train Loss: 0.0515, Val Loss: 0.0480\n",
      "Epoch 400/1000, Train Loss: 0.0511, Val Loss: 0.0483\n",
      "Epoch 500/1000, Train Loss: 0.0511, Val Loss: 0.0483\n",
      "Epoch 600/1000, Train Loss: 0.0511, Val Loss: 0.0483\n",
      "Epoch 700/1000, Train Loss: 0.0511, Val Loss: 0.0483\n",
      "Epoch 800/1000, Train Loss: 0.0511, Val Loss: 0.0483\n",
      "Epoch 900/1000, Train Loss: 0.0511, Val Loss: 0.0483\n",
      "Epoch 1000/1000, Train Loss: 0.0511, Val Loss: 0.0483\n"
     ]
    }
   ],
   "source": [
    "AmpOpT_pred_model = AmpOpT_NN()\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(AmpOpT_pred_model.parameters(), lr = learning_rate)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    AmpOpT_pred_model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for X_batch, Y_batch in train_loader:\n",
    "        output = AmpOpT_pred_model(X_train)\n",
    "        l = loss(output, Y_train)\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += l.item()\n",
    "\n",
    "    train_loss /= len(train_loader) \n",
    "\n",
    "    AmpOpT_pred_model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_val_batch, Y_val_batch in val_loader:\n",
    "            val_pred = AmpOpT_pred_model(X_val_batch)\n",
    "            val_loss += loss(val_pred, Y_val_batch).item()\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, measures):\n",
    "    model.eval()\n",
    "    measures_normalized = scaler_X.transform([measures])\n",
    "    measures_tensor = torch.tensor(measures_normalized, dtype=torch.float32)\n",
    "    predictions = model(measures_tensor).detach().numpy()\n",
    "    return scaler_Y.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ganho DC: Max = 2836.1963 ; Min = 0.058187954\n",
      "Freq Corte: Max = 114815360.0 ; Min = 436.51584\n",
      "Slew Rate: Max = 16696646.0 ; Min = 30904.166\n"
     ]
    }
   ],
   "source": [
    "print('Ganho DC: Max =', max(X_medidas[:,0]), '; Min =', min(X_medidas[:,0]))\n",
    "print('Freq Corte: Max =', max(X_medidas[:,1]), '; Min =', min(X_medidas[:,1]))\n",
    "print('Slew Rate: Max =', max(X_medidas[:,2]), '; Min =', min(X_medidas[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larguras de canal previstas: [[6.48590049e-06 7.19695436e-06 7.50623167e-06 8.04592673e-06\n",
      "  1.18833475e+01]]\n"
     ]
    }
   ],
   "source": [
    "novas_medidas = [2.5e3, 10e3, 15e6]\n",
    "larguras_previstas = predict(AmpOpT_pred_model, novas_medidas)\n",
    "print(\"Larguras de canal previstas:\", larguras_previstas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
